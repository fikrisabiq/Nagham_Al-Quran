{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import and associate Google Drive with Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mfFRprzBRRIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ae9801-a862-4837-f50d-179acf15e88a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tl3x55rSWbR5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bO5BP9tqIM_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d732a3e-07c4-4c73-b490-c25d8d599f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "json_file = open('/content/drive/MyDrive/Colab Notebooks/Audio Nagham Recognition/trained_models/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/Audio Nagham Recognition/trained_models/model_weights.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CYzndZrsIM_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db8d9ed-d20d-43a2-a543-2bbab5912fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Audio Nagham Recognition/trained_models/scaler2.pickle', 'rb') as f:\n",
        "    scaler2 = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Audio Nagham Recognition/trained_models/encoder2.pickle', 'rb') as f:\n",
        "    encoder2 = pickle.load(f)\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FA_OQ1ZhIM_r"
      },
      "outputs": [],
      "source": [
        "def zcr(data,frame_length,hop_length):\n",
        "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(zcr)\n",
        "def rmse(data,frame_length=2048,hop_length=512):\n",
        "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(rmse)\n",
        "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
        "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
        "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
        "\n",
        "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
        "    result=np.array([])\n",
        "\n",
        "    result=np.hstack((result,\n",
        "                      zcr(data,frame_length,hop_length),\n",
        "                      rmse(data,frame_length,hop_length),\n",
        "                      mfcc(data,sr,frame_length,hop_length)\n",
        "                     ))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Vb9-XUC1IM_s"
      },
      "outputs": [],
      "source": [
        "def get_predict_feat(path):\n",
        "    d, s_rate= librosa.load(path, duration=35.0, offset=0.3)\n",
        "    res=extract_features(d)\n",
        "    result=np.array(res)\n",
        "    target_shape = (1,33176)\n",
        "    zeroes_array = np.zeros(target_shape)\n",
        "    zeroes_array[0, :result.size] = result\n",
        "    i_result = scaler2.transform(zeroes_array)\n",
        "    final_result=np.expand_dims(i_result, axis=2)\n",
        "\n",
        "    return final_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_naghams={\n",
        "\n",
        "          # Bayati ashli\n",
        "          1:'Bayati Ashli Qorror',\n",
        "          # Bayati nawa\n",
        "          2:'Bayati Ashli Nawa',\n",
        "          # Bayati syuti\n",
        "          3:'Bayati Syuri',\n",
        "          4:'Bayati Syuri',\n",
        "          5:'Bayati Syuri',\n",
        "          # Bayati husaini\n",
        "          6:'Bayati Husaini',\n",
        "          7:'Bayati Husaini',\n",
        "          8:'Bayati Husaini',\n",
        "          9:'Bayati Husaini',\n",
        "          10:'Bayati Husaini',\n",
        "          11:'Bayati Husaini',\n",
        "          # Bayati ashli jawab\n",
        "          12:'Bayati Ashli Jawab',\n",
        "          13:'Bayati Ashli Jawab',\n",
        "          14:'Bayati Ashli Jawab',\n",
        "          # Bayati syuri jawabuljawab\n",
        "          15:'Bayati Syuri Jawabuljawab',\n",
        "          47:'Bayati Syuri Jawabuljawab',\n",
        "          # Shaba\n",
        "          16:'Shaba Ashli',\n",
        "          17:'Shaba Ashli',\n",
        "          18:'Shaba Ashli',\n",
        "          19:'Shaba Ashli',\n",
        "          # Jawab shaba\n",
        "          20:'Jawab Shaba',\n",
        "          # Jawab shaba maalajam\n",
        "          21:'Jawab Shaba Maalajam',\n",
        "          # Jawab shaba maalbastanjar\n",
        "          22:'Jawab Shaba Maalbastanjar',\n",
        "          # Hijaz ashli\n",
        "          23:'Hijaz Ashli',\n",
        "          24:'Hijaz Ashli',\n",
        "          25:'Hijaz Ashli',\n",
        "          26:'Hijaz Ashli',\n",
        "          27:'Hijaz Ashli',\n",
        "          28:'Hijaz Ashli',\n",
        "          # Hijaz kar\n",
        "          29:'Hijaz Kar',\n",
        "          # Hijaz karkur\n",
        "          30:'Hijaz Karkur',\n",
        "          # Hijaz kur\n",
        "          31:'Hijaz Kur',\n",
        "          # Rast ashli\n",
        "          32:'Rast Ashli',\n",
        "          33:'Rast Ashli',\n",
        "          34:'Rast Ashli',\n",
        "          35:'Rast Ashli',\n",
        "          # Rast alanawa\n",
        "          36:'Rast Alanawa',\n",
        "          37:'Rast Alanawa',\n",
        "          38:'Rast Alanawa',\n",
        "          # Rast zunjiran\n",
        "          48:'Rast zunjiran',\n",
        "          # Sika ashli\n",
        "          39:'Sika Ashli',\n",
        "          # Sika turki\n",
        "          40:'Sika Turki',\n",
        "          # Sika mishri\n",
        "          41:'Sika Mishri',\n",
        "          # Jiharkah ashli\n",
        "          42:'Jiharkah Ashli',\n",
        "          # Jiharkah jawab\n",
        "          43:'Jiharkah Jawab',\n",
        "          44:'Jiharkah Jawab',\n",
        "          # Nahawand ashli\n",
        "          45:'Nahawand Ashli',\n",
        "          # Nahawand jawab\n",
        "          46:'Nahawand Jawab'\n",
        "\n",
        "          }"
      ],
      "metadata": {
        "id": "jUgAxgGGUJLq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "id": "aHv_izoQnFWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7531924-7a36-49bf-8a19-e08ae7dee22f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "Gt82AkMyrXir"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_and_predict(file_path):\n",
        "    fixed_file_path = fix_wav(file_path)\n",
        "    res = get_predict_feat(fixed_file_path)\n",
        "    predictions = loaded_model.predict(res)\n",
        "    nagham_index = np.argmax(predictions[0])\n",
        "    nagham_label = category_naghams[nagham_index + 1]\n",
        "    print(\"Predicted:\", nagham_label)"
      ],
      "metadata": {
        "id": "VSpHnKk1shEm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_wav(file_path):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    audio.export(file_path, format=\"wav\")\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "FndRBeP7Igad"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Audio Nagham Recognition/dataset/A.1_tausyih_bayati_ashli_qorror_ar-rahman/1.0_ar-rahman_bayyati_ashli_qorror_v1_b.wav'\n",
        "fix_and_predict(file_path)"
      ],
      "metadata": {
        "id": "rS_TQzWKslTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5aa7a9-d3ea-47b1-831c-d7166f6e5498"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 306ms/step\n",
            "Predicted: Bayati Husaini\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 107620,
          "sourceId": 256618,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 316368,
          "sourceId": 639622,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 325566,
          "sourceId": 653195,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 338555,
          "sourceId": 671851,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 3468263,
          "sourceId": 6060815,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30380,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}